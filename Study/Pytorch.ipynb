{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML1N/P7La1YW3muxw8321g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haesookimDev/MLOps/blob/main/Study/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fullstackdeeplearning.com 에서 제공한 강의를 기반으로 실습한 코드입니다.\n"
      ],
      "metadata": {
        "id": "TvxMuJuJk2pE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일부 기능 구현 코드에 오류가 있어 수정한 부분이 있습니다."
      ],
      "metadata": {
        "id": "81WPQhUkvuS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습 세팅"
      ],
      "metadata": {
        "id": "J2ZsaDUIlTcb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml2lar-kkeJ1",
        "outputId": "394bdba3-0a7a-48a4-e04e-7e58f741d938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "/content/fsdl-text-recognizer-2022-labs/lab01\n",
            "\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "lab_idx = 1\n",
        "\n",
        "if \"bootstrap\" not in locals() or bootstrap.run:\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    # change into the lab directory\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow \"hot-reloading\" of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False  # change to True re-run setup\n",
        "\n",
        "!pwd\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIS 이미지 데이터 셋(숫자 필기체) 로드"
      ],
      "metadata": {
        "id": "-MLVD4KHmQaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ],
      "metadata": {
        "id": "vbSLpgTJlRCJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다운로드한 데이터 읽어서 훈련, 검증데이터로 분리"
      ],
      "metadata": {
        "id": "vvZs9nxznBTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "\n",
        "def read_mnist(path):\n",
        "    with gzip.open(path, \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "    return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = read_mnist(datafile)"
      ],
      "metadata": {
        "id": "hNdyYtPSm-kf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "읽어온 데이터를 텐서형태로 변환 > 텐서는 GPU, TPU와 같은 가속기 메모리에서 사용 가능"
      ],
      "metadata": {
        "id": "zIAqRl14nLUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ],
      "metadata": {
        "id": "ZCWU8BkdnKG_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train, y_train, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uj25U8vn1WQ",
        "outputId": "91b2f0c1-aa0f-4ff6-99d7-fc90b4a142e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0], x_train[0, ::2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afeyWC5hoPPm",
        "outputId": "035dd0ce-2217-4709-bf17-2cf380da3dc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
              "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
              "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
              "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
              "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
              "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
              "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
              "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
              "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.ndim, y_train.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdIYHtQXoPjF",
        "outputId": "9f7e50a4-0cdb-4f0b-b3a6-b4e9b6d323be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0], y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzUnlucyoZd0",
        "outputId": "0b8cadba-9785-426a-e72a-f5af7b647f3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.), tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZP8v-etoar4",
        "outputId": "116fdd36-ce4b-47d2-b6cd-069d735ddf5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import wandb  # Tracking, 시각화할 수 있는 Tool\n",
        "\n",
        "import text_recognizer.metadata.mnist as metadata # mnist 데이터로 부터 추출한 metadata\n",
        "\n",
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx]\n",
        "\n",
        "print(y_train[idx])  # 이미지 정답\n",
        "wandb.Image(example.reshape(*metadata.DIMS)).image  # 이미지 그리기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "49G4zV6hocbf",
        "outputId": "c0b52872-de77-487f-d280-f672e43bf7cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABs0lEQVR4nO2UL4gCQRSHh0MEg2zYMGhwywZFg9XsFsEgCAuCacdkEpPBKpgsZqPRRZtYBYswggg2maBBQRYVQZA3c2FgkcP7s96GC/e132P4ePPmMQj98893YIwxxm4khAghCCFPD7/9xBiNRsfjca/XkzEQCJimKYTQdf31Ntvt9mazsSxLxng8DgCcc8MwXu9UURSMcSwWk7HT6SCEGGOU0hfbJITcbrf1eu3O9HA4AIA7Dc+Ew2HGGOe81WrJiqqqjuNwzj97pe/pdrsAYNt2KBSSlWazCQAA8LgMHkgkEqfTabvdJpNJ2aNpmrvdTkoppZlMxpvRMAzHcQCgVquVy2XbtmV0WSwWkUjEg1HTNDm4R4sbj8djoVD44vqBp9VqtaooyuVyWS6XCKH5fL5arXRdbzQaCKF6vT4cDj3dGyGESqXSdDp1F1OSzWZlp6qqejY+RdM0xhgAzGazYDDoj9SyLM75+XyWm+APg8GAc77f730zVioVzrkQIp/P/+T889f/QCqVEkJQSieTye/ae0D+IP1+3zdjLpe73+8AUCwWfZOm0+nr9ToajXwz/iHeAWoU9Lq0uZE2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "#실습을 위한 단일 레이어의 가중치와 bias를 초기화 Grediant Descent를 통한 가중치 수정을 위한 requires_grad 옵션 활성화\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ],
      "metadata": {
        "id": "MfsTd8YnpGtp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#선형 회귀 모델 레이어 선언 입력과 return 타입은 torch.Tensor\n",
        "# @는 행렬연산자\n",
        "def linear(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ weights + bias"
      ],
      "metadata": {
        "id": "L1P1zsk3ql1t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#선형 회귀 모델의 출력에 softmax값을 취함\n",
        "def softmax(x: torch.Tensor, dim: int=0) -> torch.Tensor:\n",
        "    exp_x=torch.exp(x)\n",
        "    return exp_x/torch.sum(exp_x, axis=1)[:, None]\n",
        "\n",
        "def model(xb: torch.Tensor) -> torch.Tensor:\n",
        "    return softmax(linear(xb))"
      ],
      "metadata": {
        "id": "NuCbqG7zq6AY"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64  # 배치 사이즈\n",
        "\n",
        "xb = x_train[0:bs]  # 입력의 첫번째 배치\n",
        "outs = model(xb)  # 첫번째 배치 결과\n",
        "\n",
        "print(outs[0], outs.shape)  # 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK_fLYHDtOBi",
        "outputId": "3e097b18-59bf-4e2e-c4f2-c698f959dfdb"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0627, 0.0960, 0.2045, 0.0923, 0.0921, 0.1048, 0.1303, 0.0384, 0.1038,\n",
            "        0.0750], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정확도 계산 전체 예측결과중 제대로 예측한 비율\n",
        "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "metadata": {
        "id": "BjC8s8WItr_w"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yb = y_train[0:bs]\n",
        "\n",
        "acc = accuracy(outs, yb)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ndFcTZwuAmu",
        "outputId": "a2489fe0-23d5-4945-9916-2c52650ffdb3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0312)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정확도 수치 기반으로 역전파\n",
        "try:\n",
        "    acc.backward()\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzddUEMWuDvj",
        "outputId": "464eca55-c1d4-4928-856d-90ac9a3fa98a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "element 0 of tensors does not require grad and does not have a grad_fn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outs.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZLrNXh2957W",
        "outputId": "5fd20982-4017-40ea-a726-ba487851a9a6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vjQUNV8_-eM",
        "outputId": "f64d6770-4f11-47b4-b21d-633d5fa7ee95"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
              "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
              "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wV-b5AYuADas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#크로스 엔트로피 실제 값과 예측값 사이의 교차 엔트로피 계산\n",
        "\n",
        "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return -torch.log(output[range(target.shape[0]), target]).mean()\n",
        "\n",
        "loss_func = cross_entropy"
      ],
      "metadata": {
        "id": "PtnHwoOxuUoF"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWVvUs9__Hy0",
        "outputId": "33b735ac-ea35-4435-e4f9-4e947baad113"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3170, grad_fn=<NegBackward0>) tensor(2.3026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_func(outs, yb)\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "TNGaYBYJ_Jm-"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up-HT8JeAM0U",
        "outputId": "ca01dfb5-9827-4bca-a0e7-9766f68d4979"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0081, -0.0146,  0.0947, -0.0175, -0.0381,  0.0247,  0.0126, -0.0299,\n",
              "         0.0065, -0.0303])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5  # 학습률\n",
        "epochs = 2  # 훈련 에포크\n",
        "\n",
        "for epoch in range(epochs):  # 에포크 반복\n",
        "    for ii in range((n - 1) // bs + 1):  # 배치사이즈 만큼 분할\n",
        "        start_idx = ii * bs  # 배치의 시작 인덱스\n",
        "        end_idx = start_idx + bs  # 배치 마지막 인덱스\n",
        "\n",
        "        # 배치만큼 데이터 분할\n",
        "        xb = x_train[start_idx:end_idx]\n",
        "        yb = y_train[start_idx:end_idx]\n",
        "\n",
        "        # 모델 실행\n",
        "        pred = model(xb)\n",
        "\n",
        "        # 손실값 추출\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        # 역전파 과정\n",
        "        loss.backward()\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        with torch.no_grad():  # no_grad() with statement에 포함해 autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n",
        "            # SGD learning rule: update with negative gradient scaled by lr\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "\n",
        "            # gradient를 계산할 때 pytorch가 자동으로 gradient 값을 누적\n",
        "            # .backward()이후 각 파라미터의 .grad에 누적, 나중 .backward()에 영향을 끼침\n",
        "            # .grad에 원래 누적된 값을 치워주고 (=0으로 초기화 해주고) gradient를 계산\n",
        "            # .grad.zero_()는 파라미터에 적용 weight .grad.zero_(), bias.grad.zero_()\n",
        "            #  zero_grad()는 옵티마이저에 적용 모든 파라미터에 .grad.zero_()를 적용 불편, optimizer를 처음에 부를 때 어떤 파라미터를 최적화하고 싶은지 정의\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ],
      "metadata": {
        "id": "hM9xxCzMAOil"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUbriCNrCEqw",
        "outputId": "a1075b9f-0e82-4313-f5cc-6a57dcd14fc8"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0805, grad_fn=<NegBackward0>) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx:idx+1]\n",
        "\n",
        "out = model(example)\n",
        "\n",
        "print(out.argmax())\n",
        "wandb.Image(example.reshape(28, 28)).image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "VGvXp9NMCHRb",
        "outputId": "3e11a7ea-b95c-413d-97e2-d4ce129688cc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAY0lEQVR4nO2USwqAUAhFH21Md6Y7U1dmAyEa1Q2EKDwjR0fFz1rDW6hqZjZLMxOXbs3JRwpKmfkj0gNV7ZeCjPQed6+AiJ5uwhVmVj8FWQC0/YjAK/jZoM6ISGf+mhV4qUMzOxqDJYYiUUNJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 위에 구현한 것들을 pytorch에서 구현된 라이브러리를 호출해 사용"
      ],
      "metadata": {
        "id": "7Mno1CtiCtLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ],
      "metadata": {
        "id": "LxVM8EBrCOhO"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb)) #위에서 나온 결과와 동일함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVH9v589C4ty",
        "outputId": "e75e664d-1a54-40dc-cd21-82548bafb65c"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0805, grad_fn=<NllLossBackward0>) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # 클래스를 선언할때 초기화되는 부분\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))"
      ],
      "metadata": {
        "id": "GsH-0mEZC6UD"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, xb: torch.Tensor) -> torch.Tensor:# 모델 훈련, 예측 수행할때 실핸하는 부분\n",
        "    return xb @ self.weights + self.bias"
      ],
      "metadata": {
        "id": "-TOt8kuvDi2x"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNISTLogistic.forward = forward #정의한 forward 함수를 오버라이딩\n",
        "\n",
        "model = MNISTLogistic()  # 모듈 클래스 초기화\n",
        "print(model(xb)[:4])\n",
        "\n",
        "loss = loss_func(model(xb), yb)\n",
        "loss.backward()\n",
        "\n",
        "print(model.weights.grad[::17,::2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2aHAknDcDw",
        "outputId": "c047db1e-8444-408f-f7d9-3b5d8b9f92b9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1180,  0.5516, -0.7858, -0.1832, -0.0513,  0.2706,  0.0476,  0.0681,\n",
            "         -0.5595, -0.1869],\n",
            "        [ 0.1686,  0.3934, -0.6926, -0.4720, -0.1936,  0.5853, -0.0631, -0.0033,\n",
            "         -0.4334, -0.0016],\n",
            "        [-0.0560,  0.3204, -0.5259, -0.0075, -0.0679,  0.1063, -0.0378,  0.0783,\n",
            "         -0.4344, -0.2066],\n",
            "        [-0.1292,  0.1544, -0.5223, -0.2212,  0.0370,  0.2705,  0.0609,  0.0114,\n",
            "          0.1091, -0.1857]], grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 6.9874e-03,  5.4888e-03,  5.6481e-03,  6.4327e-03,  5.9681e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-3.2592e-02, -2.8196e-02,  4.1909e-02,  5.2353e-02, -1.4540e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-3.1453e-02,  9.0750e-03, -3.9394e-02,  1.8804e-02, -4.7805e-02],\n",
            "        [ 1.9096e-02,  1.4608e-02,  1.6505e-02,  2.0662e-02, -5.1991e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-7.3841e-02,  7.3542e-03,  4.0877e-02,  4.7162e-02, -3.7352e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-9.9310e-02,  1.3706e-02,  7.0046e-03,  2.5073e-02, -2.2606e-02],\n",
            "        [-6.5704e-02,  3.5869e-02,  5.0227e-02,  5.9029e-02, -1.2879e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.5128e-02,  1.7621e-02,  1.9271e-02,  2.5520e-02, -5.0295e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-5.7049e-02,  2.1374e-03,  7.4723e-03,  5.4880e-03,  3.7167e-03],\n",
            "        [ 1.9701e-02,  1.2592e-02, -5.7482e-02,  2.4722e-02, -4.6484e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.8935e-02,  2.6111e-02, -2.0247e-02,  4.7093e-02, -8.6341e-02],\n",
            "        [ 6.9604e-03,  3.2046e-03, -5.4950e-02,  8.1962e-03,  4.5243e-03],\n",
            "        [-2.8092e-02,  1.3896e-03,  4.2072e-03,  3.3633e-03,  2.5245e-03],\n",
            "        [-1.5416e-02, -3.6013e-02, -5.2870e-02,  5.2031e-02, -7.4241e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-2.1429e-02, -3.1104e-02, -4.4719e-02,  6.0580e-02, -9.9745e-02],\n",
            "        [-5.5946e-02,  6.8905e-03,  8.5452e-03,  9.0169e-03,  5.7998e-03],\n",
            "        [-1.3553e-03,  1.3203e-04,  1.7252e-04,  1.7968e-04,  1.0456e-04],\n",
            "        [-5.7137e-02,  2.6328e-02, -8.0042e-03,  4.2514e-02, -1.2016e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-8.9704e-02,  1.3983e-02, -9.8773e-03,  5.8341e-02, -7.9055e-02],\n",
            "        [-5.6016e-02,  6.8627e-03,  8.4661e-03,  8.9302e-03,  5.7613e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-1.0728e-01, -1.2614e-02,  7.1473e-02,  8.2786e-02, -1.2151e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.4024e-02,  1.0340e-02,  1.2127e-02,  1.7958e-02, -5.0574e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 7.8210e-04,  4.5719e-04,  8.9023e-04,  9.2460e-04,  6.9472e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YaEJOuXDeR8",
        "outputId": "e8508498-8f5b-4979-a455-f72e50735bfa"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0618,  0.0410,  0.0120,  ..., -0.0034,  0.0596, -0.0061],\n",
            "        [-0.0083, -0.0227,  0.0369,  ..., -0.0205,  0.0271, -0.0072],\n",
            "        [-0.0182, -0.0017, -0.0283,  ..., -0.0311,  0.0007, -0.0333],\n",
            "        ...,\n",
            "        [-0.0360, -0.0289,  0.0415,  ..., -0.0212,  0.0080,  0.0649],\n",
            "        [ 0.0218, -0.0030,  0.0368,  ..., -0.0038, -0.0193, -0.0091],\n",
            "        [ 0.0247, -0.0573,  0.0454,  ...,  0.0955,  0.0307,  0.0241]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for ii in range((n - 1) // bs + 1):\n",
        "            start_idx = ii * bs\n",
        "            end_idx = start_idx + bs\n",
        "            xb = x_train[start_idx:end_idx]\n",
        "            yb = y_train[start_idx:end_idx]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():  # 모델의 파라미터 업데이트\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit()"
      ],
      "metadata": {
        "id": "vb44z9_PD4QI"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQa-1E8hEDTe",
        "outputId": "237d7790-c839-4a58-80e7-6c04a067b422"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치에 구현된 레이어 사용"
      ],
      "metadata": {
        "id": "jdz7gFFMEJs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_XD4VSxEFZj",
        "outputId": "c9de31b3-1291-4583-a014-c843a4ad6cec"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.nn.Modules:\n",
            "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
            "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
            "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
            "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
            "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
            "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
            "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
            "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
            "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
            "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
            "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
            "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
            "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
            "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
            "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
            "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
            "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
            "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
            "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
            "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
            "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
            "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
            "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
            "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad1d,\n",
            "\tZeroPad2d, ZeroPad3d, ConstantPad1d, ConstantPad2d, ConstantPad3d,\n",
            "\tBilinear, CosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
            "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
            "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
            "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
            "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
            "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
            "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
            "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle, CircularPad1d,\n",
            "\tCircularPad2d, CircularPad3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)  # 입력 크기 784 출력 10 (클래스 수)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)  # 선형모델 선언"
      ],
      "metadata": {
        "id": "6u6NAFDeETT1"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "print(loss_func(model(xb), yb))  # loss is still close to 2.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJMmUcWWErVI",
        "outputId": "ea60cc65-233f-4471-bcf2-a506c8b300ba"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3510, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.children()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0RFGV9SEtd6",
        "outputId": "bda5324e-873d-4c55-9d09-2088f89f4492"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJUZoNrMEu7_",
        "outputId": "3ecca259-3934-4401-88d3-4c2a13c8a087"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0030, -0.0112, -0.0256,  ..., -0.0068,  0.0033,  0.0197],\n",
            "        [-0.0220, -0.0283,  0.0276,  ...,  0.0117, -0.0098, -0.0109],\n",
            "        [-0.0229,  0.0015,  0.0125,  ...,  0.0019, -0.0232, -0.0326],\n",
            "        ...,\n",
            "        [-0.0331, -0.0261,  0.0340,  ..., -0.0104, -0.0174,  0.0219],\n",
            "        [ 0.0081,  0.0263,  0.0020,  ..., -0.0267,  0.0031, -0.0031],\n",
            "        [-0.0073,  0.0156,  0.0299,  ...,  0.0250,  0.0042,  0.0044]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0166,  0.0085,  0.0179,  0.0009, -0.0122,  0.0345, -0.0011, -0.0182,\n",
            "         0.0037,  0.0023], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "#기존에 구현한 옵티마이저는 SGD를 이용했으나 Adam이 더 성능이 좋음\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "jgPgM4q5Ewcz"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "print(\"before training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs\n",
        "        end_idx = start_idx + bs\n",
        "        xb = x_train[start_idx:end_idx]\n",
        "        yb = y_train[start_idx:end_idx]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(\"after training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTqZzmNRE3zJ",
        "outputId": "4d365df4-b293-41d7-cb0f-68b512fd3e9e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training:\n",
            "\ttensor(2.3173, grad_fn=<NllLossBackward0>)\n",
            "after training:\n",
            "\ttensor(0.8501, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 새로운 데이터"
      ],
      "metadata": {
        "id": "ivX7C4IeGzgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.data.util import BaseDataset\n",
        "\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "7qIZCgahFFAR"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[ii * bs: ii * bs + bs]  # xb and yb in one line!\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i30R9Uw1G13B",
        "outputId": "b3b7ff4b-482f-4612-a9c1-6216b5bb9293"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8564, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)"
      ],
      "metadata": {
        "id": "iVLaop-LG4Oe"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BaseDataset??"
      ],
      "metadata": {
        "id": "MpCBXz1MHWnB"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
        "    opt = configure_optimizer(self)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "MNISTLogistic.fit = fit"
      ],
      "metadata": {
        "id": "BkGCxQxGG9j_"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTNKbYGTG_4Q",
        "outputId": "154055e6-b01e-4ee3-daf7-3857a2c15f4a"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8562, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.models.mlp import MLP\n",
        "\n",
        "\n",
        "MLP.fit = fit  # attach our fitting loop"
      ],
      "metadata": {
        "id": "v_0x_keEHBbg"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.forward??"
      ],
      "metadata": {
        "id": "Rea4I3nRHHmz"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.__init__??"
      ],
      "metadata": {
        "id": "wkmALgTGHKEL"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits_to_9 = list(range(10))\n",
        "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
        "data_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpr4DFPMHMrp",
        "outputId": "a2346dc8-eb1c-40a1-fe1c-43abc90792fd"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_dims': (784,),\n",
              " 'mapping': {0: '0',\n",
              "  1: '1',\n",
              "  2: '2',\n",
              "  3: '3',\n",
              "  4: '4',\n",
              "  5: '5',\n",
              "  6: '6',\n",
              "  7: '7',\n",
              "  8: '8',\n",
              "  9: '9'}}"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(data_config)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plzB5mdHHTnO",
        "outputId": "a8fce709-a580-48db-996c-eabbd26e62b9"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EojB0F_bH2eJ",
        "outputId": "e95305bd-6684-46c2-ab17-a80f330314d0"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0272, -0.0230,  0.0161,  ...,  0.0141, -0.0187, -0.0055],\n",
              "        [-0.0314,  0.0281, -0.0129,  ..., -0.0020,  0.0331,  0.0247],\n",
              "        [-0.0142, -0.0088, -0.0219,  ...,  0.0343, -0.0313, -0.0311],\n",
              "        ...,\n",
              "        [ 0.0218, -0.0122, -0.0005,  ..., -0.0196,  0.0139,  0.0143],\n",
              "        [ 0.0343, -0.0233,  0.0190,  ...,  0.0164, -0.0012, -0.0270],\n",
              "        [ 0.0045,  0.0095, -0.0269,  ...,  0.0076,  0.0275,  0.0043]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"before training:\", loss_func(model(xb), yb))\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
        "fit(model, train_dataloader)\n",
        "\n",
        "print(\"after training:\", loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxj7f7vWH9pY",
        "outputId": "ff62343e-4608-4531-b685-3e3afcd1518a"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training: tensor(2.3059, grad_fn=<NllLossBackward0>)\n",
            "after training: tensor(0.3664, grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 28.6 s, sys: 44.4 ms, total: 28.6 s\n",
            "Wall time: 28.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print(\"☹️\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUvgnT_eH4Yi",
        "outputId": "d9303b07-efb8-465f-8c91-264348680125"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "☹️\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "loss_func(model(xb.to(device)), yb.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GdvmwKeILYG",
        "outputId": "c0a8f7d6-2bfb-424a-8b7d-169b046507c1"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1620, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def push_to_device(tensor):\n",
        "    return tensor.to(device)\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)"
      ],
      "metadata": {
        "id": "66edhQiPIMua"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pilYHm_NIWUN",
        "outputId": "672d38cb-a09d-490c-f36d-58f69f196246"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2254, grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 28.4 s, sys: 21.8 ms, total: 28.4 s\n",
            "Wall time: 28.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataModule:\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    def __init__(self, dir, bs=32):\n",
        "        self.dir = dir\n",
        "        self.bs = bs\n",
        "        self.path = self.dir / self.filename\n",
        "\n",
        "    def prepare_data(self):\n",
        "        if not (self.path).exists():\n",
        "            content = requests.get(self.url + self.filename).content\n",
        "            self.path.open(\"wb\").write(content)\n",
        "\n",
        "    def setup(self):\n",
        "        with gzip.open(self.path, \"rb\") as f:\n",
        "            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "\n",
        "        x_train, y_train, x_valid, y_valid = map(\n",
        "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        "            )\n",
        "\n",
        "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.valid_ds, batch_size=2 * self.bs, shuffle=False)"
      ],
      "metadata": {
        "id": "6ajJv9arIknZ"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self: nn.Module, datamodule):\n",
        "    datamodule.prepare_data()\n",
        "    datamodule.setup()\n",
        "\n",
        "    val_dataloader = datamodule.val_dataloader()\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
        "\n",
        "    print(\"before start of training:\", valid_loss / len(val_dataloader))\n",
        "\n",
        "    opt = configure_optimizer(self)\n",
        "    train_dataloader = datamodule.train_dataloader()\n",
        "    for epoch in range(epochs):\n",
        "        self.train()\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
        "\n",
        "        print(epoch, valid_loss / len(val_dataloader))\n",
        "\n",
        "\n",
        "MNISTLogistic.fit = fit\n",
        "MLP.fit = fit"
      ],
      "metadata": {
        "id": "MyKC9UxYIZRs"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=32)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ypCXGfmIr75",
        "outputId": "2ac0ce25-ce4d-463b-82d6-8cdc337d9ac1"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before start of training: tensor(2.3043)\n",
            "0 tensor(0.1672)\n",
            "1 tensor(0.1130)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.__init__??"
      ],
      "metadata": {
        "id": "QE3x2cblItd8"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from argparse import Namespace  # you'll need this\n",
        "\n",
        "args = None  # edit this\n",
        "\n",
        "epochs = 2  # used in fit\n",
        "bs = 32  # used by the DataModule\n",
        "\n",
        "\n",
        "# used in fit, play around with this if you'd like\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "\n",
        "model = MLP(data_config, args=args)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=bs)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN3TmDI0I45G",
        "outputId": "895d6373-6b51-469b-b0bb-ad1c0170e0d7"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before start of training: tensor(2.3069)\n",
            "0 tensor(0.1686)\n",
            "1 tensor(0.1156)\n",
            "CPU times: user 54.7 s, sys: 847 ms, total: 55.6 s\n",
            "Wall time: 55.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = datamodule.val_dataloader()\n",
        "valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n",
        "valid_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOvR-_mdI49u",
        "outputId": "0d7f294f-f832-4507-d829-2686c20ce9c6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9656)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.forward??"
      ],
      "metadata": {
        "id": "5_ddiIQiMY9I"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "ujPzruQhJIi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from argparse import Namespace"
      ],
      "metadata": {
        "id": "hvLuJ-mOMzEK"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YourModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_config: dict[str, any],\n",
        "        args: Namespace = None,\n",
        "    ) -> None:  # add args and kwargs here as you like\n",
        "\n",
        "        super().__init__()\n",
        "        # use those args and kwargs to set up the submodules\n",
        "        self.args = vars(args) if args is not None else {}\n",
        "        self.data_config = data_config\n",
        "\n",
        "        input_dim = np.prod(self.data_config[\"input_dims\"])\n",
        "        num_classes = len(self.data_config[\"mapping\"])\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 500)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(500, 200)\n",
        "        self.bn = nn.BatchNorm1d(200)\n",
        "        self.fc3 = nn.Linear(200, num_classes)\n",
        "\n",
        "    def forward(self, x):  # overwrite this to use your nn.Modules from above\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "YourModel.fit = fit  # don't forget this!"
      ],
      "metadata": {
        "id": "9EiAKOhkI8ak"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = None\n",
        "\n",
        "model = YourModel(data_config, args=args)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=bs)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ZLgs2aJLmW",
        "outputId": "ebcfaf53-4ef0-450b-c9e7-52cbda92ecf7"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before start of training: tensor(2.3007)\n",
            "0 tensor(0.1815)\n",
            "1 tensor(0.1234)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = datamodule.val_dataloader()\n",
        "valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n",
        "valid_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsUDYC2uJM7I",
        "outputId": "0b1d09a3-1966-4d57-a80b-07e433bc5eec"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9647)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vc8utkBsOPq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}